{
  "model_version": {
    "name": "system.ai.dbrx_instruct",
    "version": "2",
    "creation_timestamp": 1715905413966,
    "last_updated_timestamp": 1715905413966,
    "user_id": "System user",
    "description": "This model version is a performance optimized version of `dbrx_instruct`. Refer to the [Databricks page](https://huggingface.co/collections/databricks/dbrx-6601c0852a0cdd3c59f71962) for full details around limitations, evaluated use, and broader implications. For usage of the model on Databricks, review the description of the model in the model overview.\n\n`dbrx_instruct` is licensed under the [Databricks Open Model License](https://www.databricks.com/legal/open-model-license).",
    "source": "",
    "status": "READY",
    "storage_location": "s3://system-tables-staging-us-west-2-uc-metastore-bucket/metastore/a6d4c873-c9a2-4796-aa5b-d899c6ca7cb1/models/736c046b-b1de-482b-a498-4abd40ccb4a1/versions/454be095-bcbf-4065-ad6f-76d17f176e66",
    "_creation_timestamp": "2024-05-17 00:23:34",
    "_last_updated_timestamp": "2024-05-17 00:23:34",
    "_is_unity_catalog": true,
    "_reg_model_download_uri": "s3://system-tables-staging-us-west-2-uc-metastore-bucket/metastore/a6d4c873-c9a2-4796-aa5b-d899c6ca7cb1/models/736c046b-b1de-482b-a498-4abd40ccb4a1/versions/454be095-bcbf-4065-ad6f-76d17f176e66",
    "_run_model_download_uri": "",
    "_web_ui_link": "https://v9-antfood.mycompany.com/explore/data/models/system/ai/dbrx_instruct/version/2",
    "_api_link": "https://v9-antfood.mycompany.com/api/2.0/mlflow/unity-catalog/model-versions/get?name=system.ai.dbrx_instruct&version=2"
  },
  "mlflow_model": {
    "databricks_runtime": "14.3.x-cpu-ml-scala2.12",
    "flavors": {
      "python_function": {
        "env": {
          "conda": "conda.yaml",
          "virtualenv": "python_env.yaml"
        },
        "loader_module": "mlflow.transformers",
        "python_version": "3.10.12"
      },
      "transformers": {
        "code": null,
        "components": [
          "tokenizer"
        ],
        "framework": "pt",
        "instance_type": "TextGenerationPipeline",
        "model_binary": "model",
        "pipeline_model_type": "DbrxForCausalLM",
        "source_model_name": "/local_disk0/hf/hub/models--databricks--dbrx-instruct-perf/snapshots/62d0b14009746c7d577badc912d51e544fad7fdf",
        "task": "text-generation",
        "tokenizer_type": "TiktokenTokenizerWrapper",
        "torch_dtype": "torch.float16",
        "transformers_version": "4.40.0"
      }
    },
    "metadata": {
      "curation_version": 2,
      "databricks_model_family": "DbrxForCausalLM (dbrx)",
      "databricks_model_size_parameters": "132b",
      "databricks_model_source": "model-zoo",
      "source": "huggingface",
      "source_model_name": "databricks/dbrx-instruct-perf",
      "source_model_revision": "62d0b14009746c7d577badc912d51e544fad7fdf",
      "task": "llm/v1/chat"
    },
    "mlflow_version": "2.11.2",
    "model_size_bytes": 132988650964,
    "model_uuid": "c08303d9cbe64246be78aecda47c1645",
    "saved_input_example_info": {
      "artifact_path": "input_example.json",
      "type": "json_object"
    },
    "signature": {
      "inputs": [
        {
          "type": "array",
          "items": {
            "type": "object",
            "properties": {
              "content": {
                "type": "string",
                "required": true
              },
              "role": {
                "type": "string",
                "required": true
              }
            }
          },
          "name": "messages",
          "required": true
        }
      ],
      "outputs": [
        {
          "type": "string",
          "required": true
        }
      ],
      "params": [
        {
          "name": "temperature",
          "type": "double",
          "default": 1.0,
          "shape": null
        },
        {
          "name": "max_new_tokens",
          "type": "long",
          "default": 256,
          "shape": null
        },
        {
          "name": "do_sample",
          "type": "boolean",
          "default": true,
          "shape": null
        }
      ]
    },
    "utc_time_created": "2024-05-28 23:21:59.469578"
  },
  "registered_model": {
    "name": "system.ai.dbrx_instruct",
    "creation_timestamp": 1715280423095,
    "last_updated_timestamp": 1715899122266,
    "user_id": "System user",
    "description": "\ndbrx_instruct - **preview**\n================================\n\n\nThe `dbrx_instruct` model is a text-generation model released by Databricks. It is an [MLflow](https://mlflow.org/docs/latest/index.html) model that packages\n[Hugging Face\u2019s implementation for the dbrx_instruct model](https://huggingface.co/databricks/dbrx-instruct)\nusing the [transformers](https://mlflow.org/docs/latest/models.html#transformers-transformers-experimental) \nflavor in MLflow.\n\n- Thanks to its MoE architecture, DBRX is highly efficient for inference, activating only 36 billion parameters out of a total of 132 billion trained parameters. It is capable of handling input length up to 32k tokens, and generating outputs of up to 4k tokens.\n- It is fine-tuned specifically for instruction-based use cases, and excels at a broad set of natural language tasks such as text summarization, question-answering, extraction, and coding.\n\n\n**Input:** Request that describes the conversation containing the text of instructions, where the messages field must alternate between user and assistant roles, ending with a user message. ([AWS](https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#chat-request)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/foundation-models/api-reference#chat-request))\n\n**Output:** Chat completion object that provides the next assistant message containing the generated response text in the conversation([AWS](https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#chat-response)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/foundation-models/api-reference#chat-response))\n\nFor details about the `dbrx_instruct` model, please visit [the Hugging Face model card](https://huggingface.co/databricks/dbrx-instruct).\n\nThis model is licensed under the [Databricks Open Model License](https://www.databricks.com/legal/open-model-license). By using this model, you acknowledge and agree to the license and the [Databricks Open Model Acceptable Use Policy](https://www.databricks.com/legal/acceptable-use-policy-open-model).\n\n# Usage\n\nDatabricks recommends that you primarily work with this model via Model Serving ([AWS](https://docs.databricks.com/machine-learning/model-serving/create-manage-serving-endpoints.html)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/create-manage-serving-endpoints)).\n\nNote: Model serving is not supported on GCP. \n## Deploying the model to Model Serving\nDatabricks recommends using the provisioned throughput ([AWS](https://docs.databricks.com/en/machine-learning/foundation-models/deploy-prov-throughput-foundation-model-apis.html)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/foundation-models/deploy-prov-throughput-foundation-model-apis)) experience for optimized inference of LLMs.\n\nTo create the endpoint, click the \u201cServe this model\u201d button above or use Databricks SDK to create the endpoint.\n\nTo deploy your model in provisioned throughput mode via API, you must specify `min_provisioned_throughput` and `max_provisioned_throughput` fields in your request.\n```python\nimport requests\nimport json\n\n# Get the API endpoint and token for the current notebook context\nAPI_ROOT = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiUrl().get()\nAPI_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n\nheaders = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\noptimizable_info = requests.get(\n    url=f\"{API_ROOT}/api/2.0/serving-endpoints/get-model-optimization-info/<UC LOCATION FOR MODEL>/2\",\n    headers=headers).json()\n\nif 'optimizable' not in optimizable_info or not optimizable_info['optimizable']:\n   raise ValueError(\"Model is not eligible for provisioned throughput\")\n\nchunk_size = optimizable_info['throughput_chunk_size']\n\n# Minimum desired provisioned throughput\nmin_provisioned_throughput = 2 * chunk_size\n\n# Maximum desired provisioned throughput\nmax_provisioned_throughput = 3 * chunk_size\n\n# send the POST request to create the serving endpoint\ndata = {\n    \"name\": endpoint_name,\n    \"config\": {\n        \"served_entities\": [\n            {\n                \"entity_name\": \"<UC LOCATION FOR MODEL>\",\n                \"entity_version\": \"2\",\n                \"min_provisioned_throughput\": min_provisioned_throughput,\n                \"max_provisioned_throughput\": max_provisioned_throughput,\n            }\n        ]\n    },\n}\n\nresponse = requests.post(\n    url=f\"{API_ROOT}/api/2.0/serving-endpoints\", json=data, headers=headers\n)\n\nprint(json.dumps(response.json(), indent=4))\n```\n\n\n\n## SQL transcription using ai_query\n\nTo generate the text using the endpoint, use `ai_query` ([AWS](https://docs.databricks.com/sql/language-manual/functions/ai_query.html)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/functions/ai_query)) to query the Model Serving endpoint.\nThe first parameter should be the name of the endpoint you previously created for Model Serving. The second parameter should be a string containing the instruction text.\n\nNOTE: `ai_query` is currently in Public Preview. Please sign up at [AI Functions Public Preview enrollment form](https://docs.google.com/forms/d/e/1FAIpQLScVyh5eRioqGwuUVxj9JOiKBAo0-FWi7L3f4QWsKeyldqEw8w/viewform) to try out the new feature.\n\n```sql\nSELECT\nai_query(\n  'dbrx_instruct',\n  text,\n) as generated_text\nfrom <TABLE>\n```\nYou can use `ai_query` in this manner to generate text in SQL queries or notebooks connected to Databricks SQL Pro or Serverless SQL Endpoints.\n\n## Generate the text by querying the serving endpoint\n\n\nTo query the model serving endpoint, first install the newest Databricks SDK for Python.\n\n```python\n# Upgrade to use the newest Databricks SDK\n%pip install --upgrade databricks-sdk\ndbutils.library.restartPython()\n```\n\nWith the newest Databricks SDK installed, query the serving endpoint as follows:\n```python\nfrom databricks.sdk.service.serving import ChatMessage\nfrom databricks.sdk import WorkspaceClient\n\nw = WorkspaceClient()\n\n# Change it to your own input\nmessages = [\n    {\n      \"role\": \"user\",\n      \"content\": \"Hello!\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! How can I assist you today?\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"What is Databricks?\"\n    }\n]\n\nmessages = [ChatMessage.from_dict(message) for message in messages]\nresponse = w.serving_endpoints.query(\n    name=endpoint_name,\n    messages=messages,\n)\nresponse.as_dict()\n```\n\n",
    "tags": {},
    "_creation_timestamp": "2024-05-09 18:47:03",
    "_last_updated_timestamp": "2024-05-16 22:38:42",
    "_is_unity_catalog": true,
    "_web_ui_link": "https://v9-antfood.mycompany.com/explore/data/models/system/ai/dbrx_instruct",
    "_api_link": "https://v9-antfood.mycompany.com/api/2.0/mlflow/unity-catalog/registered-models/get?name=system.ai.dbrx_instruct",
    "permissions": {
      "permissions": {
        "privilege_assignments": [
          {
            "principal": "account users",
            "privileges": [
              "EXECUTE"
            ]
          }
        ]
      },
      "effective_permissions": {
        "privilege_assignments": [
          {
            "principal": "account users",
            "privileges": [
              {
                "privilege": "EXECUTE"
              },
              {
                "privilege": "EXECUTE",
                "inherited_from_type": "SCHEMA",
                "inherited_from_name": "system.ai"
              },
              {
                "privilege": "APPLY_TAG",
                "inherited_from_type": "CATALOG",
                "inherited_from_name": "system"
              }
            ]
          }
        ]
      }
    }
  },
  "run": {
    "warning": "Model version 'system.ai.dbrx_instruct/2' has no run_id"
  }
}
